{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data (例5.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 书上题目5.1\n",
    "def create_data():\n",
    "    dataset = [['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ]\n",
    "    label = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return dataset, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set, label = create_data()\n",
    "train_data = pd.DataFrame(data_set, columns=label)\n",
    "# print(np.array(train_data.groupby('年龄')['类别'].apply(lambda x: np.array(x))))\n",
    "X_train, y_train = train_data.iloc[:, :4], train_data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data(Iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df_iris['label'] = iris.target\n",
    "df_iris.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "iris_X, iris_y = df_iris.iloc[:, :4], df_iris.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 熵函数和基尼指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(label):\n",
    "    \"\"\"\n",
    "    计算数据集的熵\n",
    "    label: 数据集样本的类别\n",
    "    \"\"\"\n",
    "    label = np.array(label)\n",
    "    hist = np.array(list(Counter(label).values()))\n",
    "    ps = hist / np.sum(hist)\n",
    "    return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "def conditional_entropy(label):\n",
    "    \"\"\"\n",
    "    计算数据集的条件熵\n",
    "    label: 按特征值分组后的每个子数据集的类别集合\n",
    "    \"\"\"\n",
    "    label = np.array(label)\n",
    "    N = 0\n",
    "    for i in label:\n",
    "        N += len(i)\n",
    "    cond_ent = 0\n",
    "    for i in label:\n",
    "        cond_ent += (len(i) / N) * entropy(i)\n",
    "    return cond_ent\n",
    "\n",
    "def info_gain(label_father, label_child):\n",
    "    \"\"\"\n",
    "    计算信息增益\n",
    "    \"\"\"\n",
    "    return entropy(label_father) - conditional_entropy(label_child)\n",
    "\n",
    "def info_gain_ratio(label_father, label_child):\n",
    "    \"\"\"\n",
    "    计算信息增益比\n",
    "    \"\"\"\n",
    "    info_gain_res = info_gain(label_father, label_child)\n",
    "    label_father = np.array(label_father)\n",
    "    N = 0\n",
    "    for i in label:\n",
    "        N += len(i)\n",
    "    cond_ent = 0\n",
    "    for i in label:\n",
    "        cond_ent += -(len(i) / N) * np.log2(len(i) / N)\n",
    "    feature_entropy = info_gain_res / cond_ent\n",
    "    return feature_entropy\n",
    "\n",
    "def gini(label):\n",
    "    \"\"\"\n",
    "    计算基尼指数\n",
    "    label: 按特征值分组后的每个子数据集的类别集合\n",
    "    \"\"\"\n",
    "    label = np.array(label)\n",
    "    N = 0\n",
    "    for i in label:\n",
    "        N += len(i)\n",
    "    gini = 0\n",
    "    for i in label:\n",
    "        num = np.array(list(dict(Counter(i)).values()))\n",
    "        p = num / len(i)\n",
    "        gini_i = sum(p * (1 - p))\n",
    "        gini += (len(i) / N) * gini_i\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3 C4.5 CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, leaf=True, label=None, feature_name=None, feature_value=None, data_label=None):\n",
    "        \"\"\"\n",
    "        leaf: 是否是叶节点\n",
    "        label: 当前叶节点所属类\n",
    "        feature_name: 节点特征名称\n",
    "        feature_value: 节点特征分类值\n",
    "        \"\"\"\n",
    "        self.leaf = leaf\n",
    "        self.label = label\n",
    "        self.feature_name = feature_name\n",
    "        self.feature_value = feature_value\n",
    "        self.tree = {}\n",
    "        self.data_label = data_label\n",
    "        \n",
    "    def addNode(self, val, node):\n",
    "        \"\"\"\n",
    "        val: 节点对应的特征值\n",
    "        node: 节点\n",
    "        \"\"\"\n",
    "        self.leaf = False\n",
    "        self.tree[val] = node\n",
    "        \n",
    "    def predict(self, features):\n",
    "        \"\"\"\n",
    "        feature: 特征向量\n",
    "        \"\"\"\n",
    "        node = self\n",
    "        while True:\n",
    "            if node.leaf is True:\n",
    "                return node.label\n",
    "            node = node.tree[features[node.feature_name]]\n",
    "            \n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        得分\n",
    "        X_test: 测试集样本特征\n",
    "        y_test: 测试集样本类别\n",
    "        \"\"\"\n",
    "        accurate_count = 0\n",
    "        N = 0\n",
    "        for i in range(len(X_test)):\n",
    "            if self.predict(dict(X_test.iloc[i])) == y_test.iloc[i]:\n",
    "                accurate_count += 1\n",
    "            N += 1\n",
    "        return accurate_count / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTree:\n",
    "    def __init__(self, epsilon=0.01, ID3=True, C45=False, CART=False):\n",
    "        self.epsilon = epsilon\n",
    "        self.ID3 = ID3\n",
    "        self.C45 = C45\n",
    "        self.CART = CART\n",
    "        self._tree = {}\n",
    "        \n",
    "    def info_gain_train(self, dataset, feature_names):\n",
    "        \"\"\"\n",
    "        返回当前数据集信息增益最大的特征名称，以及信息增益\n",
    "        dataset(DataFrame): 数据集\n",
    "        \"\"\"\n",
    "        label_name = dataset.columns[-1]\n",
    "        labels = dataset.iloc[:, -1]\n",
    "        dataset_ent = entropy(labels)\n",
    "        min_cond_entropy = float(np.inf)\n",
    "        best_feature = None\n",
    "        for feature in feature_names:\n",
    "            label_splited = np.array(dataset.groupby(feature)[label_name].apply(lambda x: np.array(x)))\n",
    "            cond_entropy = conditional_entropy(label_splited)\n",
    "            if cond_entropy < min_cond_entropy:\n",
    "                min_cond_entropy = cond_entropy\n",
    "                best_feature  = feature\n",
    "        return best_feature, (dataset_ent - min_cond_entropy)\n",
    "    \n",
    "    def info_gain_ratio_train(self, dataset, feature_names):\n",
    "        \"\"\"\n",
    "        返回当前数据集信息增益比最大的特征名称，以及信息增益比\n",
    "        dataset(DataFrame): 数据集\n",
    "        \"\"\"\n",
    "        label_name = dataset.columns[-1]\n",
    "        labels = dataset.iloc[:, -1]\n",
    "        max_info_gain_ratio = float(-np.inf)\n",
    "        best_feature = None\n",
    "        for feature in feature_names:\n",
    "            label_splited = np.array(dataset.groupby(feature)[label_name].apply(lambda x: np.array(x)))\n",
    "            res = info_gain_ratio(labels, label_splited)\n",
    "            if res > max_info_gain_ratio:\n",
    "                max_info_gain_ratio = res\n",
    "                best_feature  = feature\n",
    "        return best_feature, max_info_gain_ratio\n",
    "    \n",
    "    def gini_train(self, dataset, feature_names):\n",
    "        \"\"\"\n",
    "        返回当前数据集尼基指数最小的特征名称，以及基尼指数\n",
    "        dataset(DataFrame): 数据集\n",
    "        \"\"\"\n",
    "        label_name = dataset.columns[-1]\n",
    "        min_gini = float(np.inf)\n",
    "        best_feature = None\n",
    "        for feature in feature_names:\n",
    "            label_splited = np.array(dataset.groupby(feature)[label_name].apply(lambda x: np.array(x)))\n",
    "            res = gini(label_splited)\n",
    "            if res < min_gini:\n",
    "                min_gini = res\n",
    "                best_feature = feature\n",
    "        return best_feature, min_gini\n",
    "    \n",
    "    def train(self, dataset, features):\n",
    "        \"\"\"\n",
    "        生成树辅助函数\n",
    "        dataset(DataFrame): 数据集\n",
    "        \"\"\"\n",
    "        y_train = dataset.iloc[:, -1]\n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return Node(leaf=True, label=y_train.iloc[0], data_label=y_train)\n",
    "        if len(features) == 0:\n",
    "            return Node(leaf=True, label=y_train.value_counts().sort_values(ascending=False).index[0], data_label=y_train)\n",
    "        \n",
    "        if self.ID3==True and self.C45==False and self.CART==False:\n",
    "            best_feature, max_info_gain = self.info_gain_train(dataset, features)\n",
    "        elif self.ID3==False and self.C45==True and self.CART==False:\n",
    "            best_feature, max_info_gain = self.info_gain_ratio_train(dataset, features)\n",
    "        elif self.ID3==False and self.C45==False and self.CART==True:\n",
    "            best_feature, max_info_gain = self.gini_train(dataset, features)\n",
    "        else:\n",
    "            raise('Didn\\'t set the right decision tree type.')\n",
    "        \n",
    "        if max_info_gain < self.epsilon and not (self.ID3==False and self.C45==False and self.CART==True):\n",
    "            return Node(leaf=True, label=y_train.value_counts().sort_values(ascending=False).index[0], data_label=y_train)\n",
    "        \n",
    "        \n",
    "        node_tree = Node(leaf=False, feature_name=best_feature, data_label=y_train)\n",
    "        feature_values = dataset.loc[:, best_feature].value_counts().index\n",
    "        print(best_feature)\n",
    "        features.remove(best_feature)\n",
    "        for value in feature_values:\n",
    "            sub_dataset = dataset[dataset[best_feature] == value]\n",
    "            sub_tree = self.train(sub_dataset, features)\n",
    "            node_tree.addNode(value, sub_tree)\n",
    "            \n",
    "        return node_tree\n",
    "    \n",
    "    def fit(self, dataset):\n",
    "        \"\"\"\n",
    "        生成树\n",
    "        dataset(DataFrame): 数据集\n",
    "        \"\"\"\n",
    "        features = list(dataset.columns[:-1])\n",
    "        self._tree = self.train(dataset, features)\n",
    "        return self._tree\n",
    "    \n",
    "    def predict(self, feature):\n",
    "        \"\"\"\n",
    "        预测\n",
    "        feature(DataFrame): 特征向量\n",
    "        \"\"\"\n",
    "        feature = dict(feature)\n",
    "        return self._tree.predict(feature)\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        得分\n",
    "        X_test: 测试集样本特征\n",
    "        y_test: 测试集样本类别\n",
    "        \"\"\"\n",
    "        accurate_count = 0\n",
    "        N = 0\n",
    "        for i in range(len(X_test)):\n",
    "            if self.predict(X_test.iloc[i]) == y_test.iloc[i]:\n",
    "                accurate_count += 1\n",
    "            N += 1\n",
    "        return accurate_count / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有自己的房子\n",
      "有工作\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'否'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DTree(ID3=True, C45=False, CART=False)\n",
    "dt.fit(train_data)\n",
    "dt.predict(train_data.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有自己的房子\n",
      "有工作\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'否'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DTree(ID3=False, C45=True, CART=False)\n",
    "dt.fit(train_data)\n",
    "dt.predict(train_data.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有自己的房子\n",
      "有工作\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'否'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DTree(ID3=False, C45=False, CART=True)\n",
    "dt.fit(train_data)\n",
    "dt.predict(train_data.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_alpha(decision_tree):\n",
    "    num_leaves = 0\n",
    "    leaves_cost = 0\n",
    "    single_node_cost = 0\n",
    "    traversal_list = []\n",
    "    traversal_list.append(decision_tree)\n",
    "    while len(traversal_list) > 0:\n",
    "        current_node = traversal_list[0]\n",
    "        for node in current_node.tree.values():\n",
    "            traversal_list.append(node)\n",
    "        if current_node.leaf == True:\n",
    "            node_entropy = entropy(current_node.data_label)\n",
    "            leaves_cost += len(current_node.data_label) * node_entropy\n",
    "            num_leaves += 1\n",
    "        traversal_list.remove(current_node)\n",
    "    single_node_cost = len(decision_tree.data_label) * entropy(decision_tree.data_label)\n",
    "    alpha = (single_node_cost - leaves_cost) / (num_leaves - 1)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_pruning_helper(decision_tree):\n",
    "    min_alpha = float(np.inf)\n",
    "    pruning_node = None\n",
    "    traversal_list = []\n",
    "    for node in decision_tree.tree.values():\n",
    "        traversal_list.append(node)\n",
    "    while len(traversal_list) > 0:\n",
    "        current_node = traversal_list[0]\n",
    "        for node in current_node.tree.values():\n",
    "            if not node.leaf:\n",
    "                traversal_list.append(node)\n",
    "        alpha = cal_alpha(current_node)\n",
    "        if alpha < min_alpha:\n",
    "            min_alpha = alpha\n",
    "            pruning_node = current_node\n",
    "        traversal_list.remove(current_node)\n",
    "    pruning_node.leaf = True\n",
    "    return decision_tree\n",
    "    \n",
    "def judge(decision_tree):\n",
    "    \"\"\"\n",
    "    To judge whether the children of decision tree are all leaves.\n",
    "    \"\"\"\n",
    "    for child in decision_tree.tree.values():\n",
    "        if child.leaf == False:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def post_pruning(decision_tree, test_data=[], test_label=[]):\n",
    "    \"\"\"\n",
    "    对决策树进行后剪枝操作\n",
    "    :param decision_tree: 决策树根节点\n",
    "    :param test_data: 测试数据集\n",
    "    :param test_label: 测试数据集的标签\n",
    "    :param train_label: 训练数据集的标签\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_acc = 0\n",
    "    best_tree = None\n",
    "    sub_tree = [decision_tree]\n",
    "    while not judge(decision_tree):\n",
    "        decision_tree = post_pruning_helper(copy.deepcopy(decision_tree))\n",
    "        sub_tree.append(decision_tree)\n",
    "        \n",
    "    for tree in sub_tree:\n",
    "        acc = tree.score(test_data, test_label)\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            best_tree = tree\n",
    "    \n",
    "    return best_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有自己的房子\n",
      "有工作\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'否'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DTree(ID3=False, C45=False, CART=True)\n",
    "dt.fit(train_data)\n",
    "dt = post_pruning(dt._tree, X_train, y_train)\n",
    "dt.predict(train_data.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train , X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size=0.3)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tree_pic.dot', 'w') as f:\n",
    "    f = export_graphviz(clf, out_file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考代码: https://github.com/fengdu78/lihang-code\n",
    "\n",
    "python: 3.7.6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
